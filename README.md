# Asistente de Voz con IA Local (STT-Ollama-TTS)

Este repositorio contiene un proyecto para construir un asistente de voz que funciona completamente en tu mÃ¡quina local, utilizando tecnologÃ­as de cÃ³digo abierto. El sistema integra Reconocimiento de Voz (STT), un Modelo de Lenguaje Grande (LLM) y SÃ­ntesis de Voz (TTS) para crear una experiencia de conversaciÃ³n fluida y privada.

El proyecto principal, **`pipecat-local-agent`**, utiliza el framework `pipecat-ai` para crear un pipeline de datos en tiempo real, ofreciendo una soluciÃ³n robusta y con un rendimiento optimizado.

## ğŸ¤– DemostraciÃ³n RÃ¡pida
*(AquÃ­ irÃ­a un GIF o video corto mostrando al asistente en acciÃ³n)*

## âœ¨ CaracterÃ­sticas Principales

- **100% Local y Privado**: Todas las operaciones (STT, LLM, TTS) se ejecutan en tu propio hardware. Tus conversaciones nunca salen de tu mÃ¡quina.
- **Componentes de CÃ³digo Abierto**:
    - **STT**: `whisper` (a travÃ©s de `pipecat`) para una transcripciÃ³n rÃ¡pida y precisa.
    - **LLM**: `Ollama` con el modelo `gemma` para el razonamiento y la generaciÃ³n de respuestas.
    - **TTS**: `kokoro` para una sÃ­ntesis de voz natural y de alta calidad en espaÃ±ol.
- **Pipeline AsÃ­ncrono**: Gracias a `pipecat-ai`, el audio se procesa en un flujo continuo, permitiendo interrupciones y una latencia de respuesta muy baja.
- **SelecciÃ³n Interactiva de Dispositivos**: El agente te permite elegir el micrÃ³fono y los altavoces al inicio, evitando la necesidad de configurar IDs de dispositivo manualmente.
- **GestiÃ³n de ConversaciÃ³n**: Mantiene el historial de la conversaciÃ³n para dar respuestas contextuales.

## ğŸš€ CÃ³mo Empezar

Esta guÃ­a se centra en el proyecto principal y mÃ¡s avanzado: `pipecat-local-agent`.

### 1. Prerrequisitos

- **Hardware**:
    - Una GPU NVIDIA con soporte para CUDA es **muy recomendable** para un rendimiento Ã³ptimo, especialmente para el STT (Whisper) y el TTS (Kokoro).
- **Software**:
    - [Python 3.10+](https://www.python.org/downloads/)
    - [Git](https://git-scm.com/downloads)
    - [Ollama](https://ollama.com/) instalado y ejecutÃ¡ndose.
        - Descarga el modelo `gemma`:
          ```bash
          ollama pull gemma
          ```

### 2. InstalaciÃ³n

1.  **Clona el repositorio:**
    ```bash
    git clone https://github.com/tu-usuario/stt-ollama-tts.git
    cd stt-ollama-tts/pipecat-local-agent
    ```

2.  **Crea un entorno virtual:**
    ```bash
    python -m venv .venv
    source .venv/bin/activate
    # En Windows: .venv\Scripts\activate
    ```

3.  **Instala las dependencias:**
    El archivo `requirements.txt` se encarga de instalar `pipecat-ai` y `pyaudio`.
    ```bash
    pip install -r requirements.txt
    ```
    > **Nota sobre PyAudio**: Si encuentras errores durante la instalaciÃ³n de `pyaudio`, puede que necesites instalar las dependencias de desarrollo de PortAudio en tu sistema.
    > - En Debian/Ubuntu: `sudo apt-get install portaudio19-dev`
    > - En Mac (con Homebrew): `brew install portaudio`

### 3. EjecuciÃ³n

Con tu entorno virtual activado y `ollama` corriendo en segundo plano, ejecuta el agente:

```bash
python main.py
```

Al iniciarse, el programa te pedirÃ¡ que selecciones el dispositivo de entrada (micrÃ³fono) y el de salida (altavoces) de una lista numerada. Simplemente introduce el nÃºmero correspondiente y presiona Enter.

Â¡Listo! Habla a tu micrÃ³fono y el asistente te responderÃ¡.

## ğŸ“ Estructura del Proyecto

```
/pipecat-local-agent
â”œâ”€â”€â”€ main.py                # Punto de entrada, define y corre el pipeline de pipecat.
â”œâ”€â”€â”€ requirements.txt       # Dependencias del proyecto.
â”œâ”€â”€â”€ list_devices.py        # Utilidad para listar dispositivos de audio.
â””â”€â”€â”€ /services
     â”œâ”€â”€â”€ gemma_llm.py       # Servicio para interactuar con Ollama/Gemma.
     â”œâ”€â”€â”€ kokoro_tts.py      # Servicio para la sÃ­ntesis de voz con Kokoro.
     â””â”€â”€â”€ whisper_stt.py     # Servicio para la transcripciÃ³n con Whisper.
```

## alternative Alternativa Simple: `stt-llm-tts`

Dentro del repositorio tambiÃ©n encontrarÃ¡s la carpeta `stt-llm-tts`. Este es un agente de voz mucho mÃ¡s simple, construido con un bucle `while` secuencial en Python y sin usar el framework `pipecat`.

- **PropÃ³sito**: Es un excelente recurso educativo para entender el flujo bÃ¡sico de un asistente de voz (Escuchar -> Pensar -> Hablar) de forma lineal.
- **Uso**: Requiere editar manualmente el archivo `stt-llm-tts/main.py` para configurar los IDs de tu micrÃ³fono y altavoces. Puedes usar el script `utils/list_devices.py` para encontrarlos.
- **Dependencias**: Tiene una lista de dependencias mÃ¡s explÃ­cita en su propio `requirements.txt`.

Es una buena base si quieres experimentar con los componentes individuales antes de pasar a un framework mÃ¡s complejo como `pipecat`.

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Si tienes ideas para mejorar el asistente, por favor abre un *issue* o envÃ­a un *pull request*.

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Consulta el archivo `LICENSE` para mÃ¡s detalles.
